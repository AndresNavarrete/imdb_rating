{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport json","metadata":{"execution":{"iopub.status.busy":"2022-07-27T17:04:55.467061Z","iopub.execute_input":"2022-07-27T17:04:55.467502Z","iopub.status.idle":"2022-07-27T17:04:55.473555Z","shell.execute_reply.started":"2022-07-27T17:04:55.467469Z","shell.execute_reply":"2022-07-27T17:04:55.471903Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"First, we will load de dataset using pandas","metadata":{}},{"cell_type":"code","source":"def getDatabase():\n    credits = pd.read_csv('../input/tmdb-movie-metadata/tmdb_5000_credits.csv')\n    movies = pd.read_csv('../input/tmdb-movie-metadata/tmdb_5000_movies.csv')\n\n    credits.columns = ['id','tittle','cast','crew']\n    movies = movies.merge(credits,on='id')\n    return movies\n\nmovies = getDatabase()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-27T17:04:55.483237Z","iopub.execute_input":"2022-07-27T17:04:55.483683Z","iopub.status.idle":"2022-07-27T17:04:56.223264Z","shell.execute_reply.started":"2022-07-27T17:04:55.483648Z","shell.execute_reply":"2022-07-27T17:04:56.221989Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Clean data. Remove some useless columns and get a clean list of genres, crew members, cast and keywords.\n","metadata":{}},{"cell_type":"code","source":"def cleanDatabase(movies):\n    movies_clean = movies[movies[\"vote_count\"] > 300]\n    movies_clean[\"genres\"] = movies_clean.apply(lambda row: getValues(row[\"genres\"]), axis = 1)\n    movies_clean[\"keywords\"] = movies_clean.apply(lambda row: getValues(row[\"keywords\"]), axis = 1)\n    movies_clean[\"cast\"] = movies_clean.apply(lambda row: getValues(row[\"cast\"]), axis = 1)\n    movies_clean[\"crew\"] = movies_clean.apply(lambda row: getValues(row[\"crew\"]), axis = 1)\n\n    useful_headers = ['id',\n    'title',\n    'original_language',\n    'budget',\n    'popularity',\n    'runtime',\n    'release_date',\n    'genres',\n    'keywords',\n    'cast',\n    'crew',\n    'vote_count',\n    'vote_average']\n    return movies_clean[useful_headers]\n\n\ndef getValues(listOfDict):\n    listOfDict = json.loads(listOfDict)\n    output = list()\n    for dictionary in listOfDict:\n        name = dictionary[\"name\"]\n        nameShort = name.lower()\n        nameShort = nameShort.replace(\" \",\"\")\n        if nameShort in output:\n            continue\n        output.append(nameShort)\n    return output\n\ndf = cleanDatabase(movies)\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T17:04:56.225884Z","iopub.execute_input":"2022-07-27T17:04:56.226582Z","iopub.status.idle":"2022-07-27T17:04:57.091410Z","shell.execute_reply.started":"2022-07-27T17:04:56.226534Z","shell.execute_reply":"2022-07-27T17:04:57.090097Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  after removing the cwd from sys.path.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"       id                                     title original_language  \\\n0   19995                                    Avatar                en   \n1     285  Pirates of the Caribbean: At World's End                en   \n2  206647                                   Spectre                en   \n\n      budget  popularity  runtime release_date  \\\n0  237000000  150.437577    162.0   2009-12-10   \n1  300000000  139.082615    169.0   2007-05-19   \n2  245000000  107.376788    148.0   2015-10-26   \n\n                                         genres  \\\n0  [action, adventure, fantasy, sciencefiction]   \n1                  [adventure, fantasy, action]   \n2                    [action, adventure, crime]   \n\n                                            keywords  \\\n0  [cultureclash, future, spacewar, spacecolony, ...   \n1  [ocean, drugabuse, exoticisland, eastindiatrad...   \n2  [spy, basedonnovel, secretagent, sequel, mi6, ...   \n\n                                                cast  \\\n0  [samworthington, zoesaldana, sigourneyweaver, ...   \n1  [johnnydepp, orlandobloom, keiraknightley, ste...   \n2  [danielcraig, christophwaltz, léaseydoux, ralp...   \n\n                                                crew  vote_count  vote_average  \n0  [stephene.rivkin, rickcarter, christopherboyes...       11800           7.2  \n1  [dariuszwolski, goreverbinski, jerrybruckheime...        4500           6.9  \n2  [thomasnewman, sammendes, annapinnock, johnlog...        4466           6.3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>original_language</th>\n      <th>budget</th>\n      <th>popularity</th>\n      <th>runtime</th>\n      <th>release_date</th>\n      <th>genres</th>\n      <th>keywords</th>\n      <th>cast</th>\n      <th>crew</th>\n      <th>vote_count</th>\n      <th>vote_average</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19995</td>\n      <td>Avatar</td>\n      <td>en</td>\n      <td>237000000</td>\n      <td>150.437577</td>\n      <td>162.0</td>\n      <td>2009-12-10</td>\n      <td>[action, adventure, fantasy, sciencefiction]</td>\n      <td>[cultureclash, future, spacewar, spacecolony, ...</td>\n      <td>[samworthington, zoesaldana, sigourneyweaver, ...</td>\n      <td>[stephene.rivkin, rickcarter, christopherboyes...</td>\n      <td>11800</td>\n      <td>7.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>285</td>\n      <td>Pirates of the Caribbean: At World's End</td>\n      <td>en</td>\n      <td>300000000</td>\n      <td>139.082615</td>\n      <td>169.0</td>\n      <td>2007-05-19</td>\n      <td>[adventure, fantasy, action]</td>\n      <td>[ocean, drugabuse, exoticisland, eastindiatrad...</td>\n      <td>[johnnydepp, orlandobloom, keiraknightley, ste...</td>\n      <td>[dariuszwolski, goreverbinski, jerrybruckheime...</td>\n      <td>4500</td>\n      <td>6.9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>206647</td>\n      <td>Spectre</td>\n      <td>en</td>\n      <td>245000000</td>\n      <td>107.376788</td>\n      <td>148.0</td>\n      <td>2015-10-26</td>\n      <td>[action, adventure, crime]</td>\n      <td>[spy, basedonnovel, secretagent, sequel, mi6, ...</td>\n      <td>[danielcraig, christophwaltz, léaseydoux, ralp...</td>\n      <td>[thomasnewman, sammendes, annapinnock, johnlog...</td>\n      <td>4466</td>\n      <td>6.3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Get unique genres, cast, crew and keywords. We have a dictionary with the number of times that a specific genre/cast/etc has been used in a movie. \n","metadata":{}},{"cell_type":"code","source":"def getAllElementsFrom(columnName):\n    output = dict()\n    for listOfElements in df[columnName]:\n        for element in listOfElements:\n            if element in output.keys():\n                output[element] += 1\n            else:\n                output[element] = 1\n    return output\n\ngenres = getAllElementsFrom(\"genres\")\nkeys = getAllElementsFrom(\"keywords\")\ncrews = getAllElementsFrom(\"crew\")\ncasts = getAllElementsFrom(\"cast\")\n\nprint(\"Genres: {}\".format(len(genres)))\nprint(\"keywords: {}\".format(len(keys)))\nprint(\"crews: {}\".format(len(crews)))\nprint(\"casts: {}\".format(len(casts)))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-07-27T17:04:57.093129Z","iopub.execute_input":"2022-07-27T17:04:57.094263Z","iopub.status.idle":"2022-07-27T17:04:57.190556Z","shell.execute_reply.started":"2022-07-27T17:04:57.094214Z","shell.execute_reply":"2022-07-27T17:04:57.189304Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Genres: 19\nkeywords: 7350\ncrews: 38208\ncasts: 36837\n","output_type":"stream"}]},{"cell_type":"markdown","source":"That's a lot of people. I don't wanna train a model with that amount of columns. Let's filter the relevant information with a bare minimun apparences on the dataset. \n","metadata":{}},{"cell_type":"code","source":"def getShortList(dictionaryCount):\n    shortList = list()\n    min_apparences = 20\n    for key, count in dictionaryCount.items():\n        if count < min_apparences:\n            continue\n        shortList.append(key)\n    return shortList\n\nshort_genres = getShortList(genres)\nshort_keys = getShortList(keys)\nshort_crews = getShortList(crews)\nshort_casts = getShortList(casts)\n\nprint(\"Genres: {}\".format(len(short_genres)))\nprint(\"keywords: {}\".format(len(short_keys)))\nprint(\"crews: {}\".format(len(short_crews)))\nprint(\"casts: {}\".format(len(short_casts)))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-27T17:04:57.194334Z","iopub.execute_input":"2022-07-27T17:04:57.195290Z","iopub.status.idle":"2022-07-27T17:04:57.216450Z","shell.execute_reply.started":"2022-07-27T17:04:57.195230Z","shell.execute_reply":"2022-07-27T17:04:57.214877Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Genres: 17\nkeywords: 132\ncrews: 138\ncasts: 87\n","output_type":"stream"}]},{"cell_type":"markdown","source":"That's better. Now, let's add each relevant genre/cast/crew/keyword to the dataset as a binary column.\n","metadata":{}},{"cell_type":"code","source":"def addBinaryColumnsToDataframe(listOfKeywords, columnName):\n    for keyword in listOfKeywords:\n        newColName = \"has_{}\".format(keyword)\n        df[newColName] = df.apply(lambda row: True if keyword in row[columnName] else False, axis = 1)\n\naddBinaryColumnsToDataframe(short_genres, \"genres\")\naddBinaryColumnsToDataframe(short_keys, \"keywords\")\naddBinaryColumnsToDataframe(short_crews, \"crew\")\naddBinaryColumnsToDataframe(short_casts, \"cast\")\n","metadata":{"execution":{"iopub.status.busy":"2022-07-27T17:04:57.218186Z","iopub.execute_input":"2022-07-27T17:04:57.219088Z","iopub.status.idle":"2022-07-27T17:05:14.646532Z","shell.execute_reply.started":"2022-07-27T17:04:57.219037Z","shell.execute_reply":"2022-07-27T17:05:14.645354Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Preparing the dataset for being used. First let's get rid of some useless columns and select the vote_average columns as the target.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport copy \n\ndf_test = copy.deepcopy(df)\ntarget_name = \"vote_average\"\nnot_usefull_Columns = [\n    'id',\n    'release_date',\n    'genres',\n    'keywords',\n    'cast',\n    'crew']\n\nfor columnName in not_usefull_Columns:\n    df_test.pop(columnName)\n\ndata = df_test.drop(columns=[target_name])\ntarget = df_test[target_name]\n\ndata_train, data_test, target_train, target_test = train_test_split(\n    data, target, random_state=42)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-27T17:05:14.648109Z","iopub.execute_input":"2022-07-27T17:05:14.648425Z","iopub.status.idle":"2022-07-27T17:05:15.318225Z","shell.execute_reply.started":"2022-07-27T17:05:14.648381Z","shell.execute_reply":"2022-07-27T17:05:15.316814Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Feature Scaling with encoders. We have two different encoders: one for categorical variables and other for numerical. Then, we will combine those in a pipeline with a preprocessor. \n","metadata":{}},{"cell_type":"code","source":"from sklearn.compose import make_column_selector as selector\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import make_pipeline\n\n\nfloat_columns_selector = selector(dtype_include=\"float\")\nint_columns_selector = selector(dtype_include=\"int\")\nstr_columns_selector = selector(dtype_include=\"object\")\nbool_columns_selector = selector(dtype_include=\"bool\")\n\nnumerical_columns = float_columns_selector(data) + int_columns_selector(data)\ncategorical_columns = str_columns_selector(data) + bool_columns_selector(data)\n\ncategorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\nnumerical_preprocessor = StandardScaler()\n\n\npreprocessor = ColumnTransformer([\n    ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n    ('standard_scaler', numerical_preprocessor, numerical_columns)])\n","metadata":{"execution":{"iopub.status.busy":"2022-07-27T17:05:15.319800Z","iopub.execute_input":"2022-07-27T17:05:15.320137Z","iopub.status.idle":"2022-07-27T17:05:15.343949Z","shell.execute_reply.started":"2022-07-27T17:05:15.320105Z","shell.execute_reply":"2022-07-27T17:05:15.343103Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def getFittingSummary(regressor):\n    predictions = regressor.predict(data_test)\n    errorsSquared = (predictions - target_test) ** 2\n    \n    print('Mean Squared Error:', round(np.mean(errorsSquared), 2), 'degrees.')\n\n    score = regressor.score(data_test, target_test)\n    print('R2:', round(score, 3))","metadata":{"execution":{"iopub.status.busy":"2022-07-27T17:05:15.345184Z","iopub.execute_input":"2022-07-27T17:05:15.346206Z","iopub.status.idle":"2022-07-27T17:05:15.354337Z","shell.execute_reply.started":"2022-07-27T17:05:15.346145Z","shell.execute_reply":"2022-07-27T17:05:15.353075Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Fitting DecisionTreeRegressor to the dataset\nfrom sklearn.tree import DecisionTreeRegressor\n\nprint(\"Decision Tree Regression\")\nregressor = DecisionTreeRegressor(random_state = 0)\nmodel = make_pipeline(preprocessor, regressor)\nmodel.fit(data_train, target_train)\ngetFittingSummary(model)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T17:05:15.356180Z","iopub.execute_input":"2022-07-27T17:05:15.356776Z","iopub.status.idle":"2022-07-27T17:05:16.406786Z","shell.execute_reply.started":"2022-07-27T17:05:15.356745Z","shell.execute_reply":"2022-07-27T17:05:16.405601Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Decision Tree Regression\nMean Squared Error: 0.57 degrees.\nR2: 0.034\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fitting Random Forest Regression to the dataset\nfrom sklearn.ensemble import RandomForestRegressor\n\nprint(\"Random Forest Regression\")\nregressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\nmodel = make_pipeline(preprocessor, regressor)\nmodel.fit(data_train, target_train)\ngetFittingSummary(model)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T17:05:16.410675Z","iopub.execute_input":"2022-07-27T17:05:16.411190Z","iopub.status.idle":"2022-07-27T17:05:50.818106Z","shell.execute_reply.started":"2022-07-27T17:05:16.411137Z","shell.execute_reply":"2022-07-27T17:05:50.816937Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Random Forest Regression\nMean Squared Error: 0.27 degrees.\nR2: 0.536\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fitting Multi-layer Perceptron regressor to the dataset\nfrom sklearn.neural_network import MLPRegressor\nprint(\"Multi-layer Perceptron Regression\")\n\nregressor = MLPRegressor(hidden_layer_sizes=(20,20,20), activation='relu', solver='adam', max_iter=500)\nmodel = make_pipeline(preprocessor, regressor)\nmodel.fit(data_train, target_train)\ngetFittingSummary(model)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-27T17:05:50.819568Z","iopub.execute_input":"2022-07-27T17:05:50.819890Z","iopub.status.idle":"2022-07-27T17:06:09.198059Z","shell.execute_reply.started":"2022-07-27T17:05:50.819859Z","shell.execute_reply":"2022-07-27T17:06:09.194200Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Multi-layer Perceptron Regression\nMean Squared Error: 0.32 degrees.\nR2: 0.452\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fitting SVR to the dataset\nfrom sklearn.svm import SVR\n\nprint(\"Support Vector Regression\")\nregressor = SVR(kernel = 'rbf')\nmodel = make_pipeline(preprocessor, regressor)\nmodel.fit(data_train, target_train)\ngetFittingSummary(model)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T17:06:09.199868Z","iopub.execute_input":"2022-07-27T17:06:09.203508Z","iopub.status.idle":"2022-07-27T17:06:12.227197Z","shell.execute_reply.started":"2022-07-27T17:06:09.203439Z","shell.execute_reply":"2022-07-27T17:06:12.225827Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Support Vector Regression\nMean Squared Error: 0.26 degrees.\nR2: 0.566\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In summary, we have made some regression models to predict the socre of a movie given de IMDB information, such as crew memenber, cast, genres, budget, among others. \n\nThe best model among all tested models is the SVR.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"Bonus track: Let's see the predictions over a real set of movies rating on IMDB. Some movies are slighly inacurate, but quite close to the real rating. We predicted that \"Superman Returns\" would be a disaster and that \"The Avengers\" would be a moderate succes. \n\nI find these result quite good becouse movies that I love, like \"The Dark Knight Rises\", are predictid with less than 3% of error on its rating.","metadata":{}},{"cell_type":"code","source":"dataToShow = df_test[:25]\npredictions = model.predict(dataToShow)\nreal = list(dataToShow[target_name])\ntitles = list(dataToShow['title'])\n\nfor index, name in enumerate(titles):\n    observed = real[index]\n    predicted = predictions[index]\n    error = 100 * abs(observed - predicted) / observed\n    print(\"Prediction {}   Real   {}    Error {}% \\t| {}\".format(\n        round(predicted, 1), \n        observed,\n        round(error), \n        name))\n","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-07-27T17:06:12.228762Z","iopub.execute_input":"2022-07-27T17:06:12.229346Z","iopub.status.idle":"2022-07-27T17:06:12.341706Z","shell.execute_reply.started":"2022-07-27T17:06:12.229310Z","shell.execute_reply":"2022-07-27T17:06:12.339871Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Prediction 7.7   Real   7.2    Error 7% \t| Avatar\nPrediction 6.7   Real   6.9    Error 3% \t| Pirates of the Caribbean: At World's End\nPrediction 6.4   Real   6.3    Error 2% \t| Spectre\nPrediction 7.4   Real   7.6    Error 3% \t| The Dark Knight Rises\nPrediction 6.0   Real   6.1    Error 2% \t| John Carter\nPrediction 6.0   Real   5.9    Error 2% \t| Spider-Man 3\nPrediction 6.4   Real   7.4    Error 14% \t| Tangled\nPrediction 6.6   Real   7.3    Error 10% \t| Avengers: Age of Ultron\nPrediction 6.9   Real   7.4    Error 7% \t| Harry Potter and the Half-Blood Prince\nPrediction 6.8   Real   5.7    Error 20% \t| Batman v Superman: Dawn of Justice\nPrediction 5.5   Real   5.4    Error 1% \t| Superman Returns\nPrediction 6.1   Real   6.1    Error 0% \t| Quantum of Solace\nPrediction 7.1   Real   7.0    Error 1% \t| Pirates of the Caribbean: Dead Man's Chest\nPrediction 6.1   Real   5.9    Error 3% \t| The Lone Ranger\nPrediction 6.7   Real   6.5    Error 3% \t| Man of Steel\nPrediction 6.2   Real   6.3    Error 2% \t| The Chronicles of Narnia: Prince Caspian\nPrediction 7.5   Real   7.4    Error 1% \t| The Avengers\nPrediction 6.2   Real   6.4    Error 3% \t| Pirates of the Caribbean: On Stranger Tides\nPrediction 6.1   Real   6.2    Error 1% \t| Men in Black 3\nPrediction 6.8   Real   7.1    Error 4% \t| The Hobbit: The Battle of the Five Armies\nPrediction 6.7   Real   6.5    Error 4% \t| The Amazing Spider-Man\nPrediction 6.0   Real   6.2    Error 4% \t| Robin Hood\nPrediction 6.9   Real   7.6    Error 9% \t| The Hobbit: The Desolation of Smaug\nPrediction 5.7   Real   5.8    Error 2% \t| The Golden Compass\nPrediction 6.8   Real   6.6    Error 3% \t| King Kong\n","output_type":"stream"}]}]}